{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure Seaborn for better visuals\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('r20.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['ID','NAME','BRANCH', 'CGPA', 'RANK', 'E1SEM1', 'E1SEM2', 'E2SEM1', 'E2SEM2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['BRANCH']==\"CSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BRANCH'] = pd.factorize(data['BRANCH'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Average_Past_Marks'] = data[['E1SEM1', 'E1SEM2', 'E2SEM1']].mean(axis=1)\n",
    "\n",
    "data['Change_E1SEM1_E1SEM2'] = data['E1SEM2'] - data['E1SEM1']\n",
    "data['Change_E2SEM1_E2SEM2'] = data['E2SEM2'] - data['E2SEM1']\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "features = data[['E1SEM1', 'E1SEM2', 'E2SEM1', 'Average_Past_Marks', 'Change_E1SEM1_E1SEM2']]\n",
    "target = data['E2SEM2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with Gradient Boosting\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MAE:\", -grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model with Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare actual and predicted marks\n",
    "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "\n",
    "# Plotting the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=comparison, x='Actual', y='Predicted')\n",
    "plt.plot([min(comparison['Actual']), max(comparison['Actual'])],\n",
    "         [min(comparison['Actual']), max(comparison['Actual'])],\n",
    "         color='red', lw=2)  # Perfect prediction line\n",
    "plt.title('Actual vs. Predicted Marks')\n",
    "plt.xlabel('Actual Marks')\n",
    "plt.ylabel('Predicted Marks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the Data\n",
    "# Assuming your data is in a CSV file named 'data.csv'\n",
    "data = pd.read_csv('r20.csv')\n",
    "\n",
    "# Step 2: Data Selection\n",
    "# Select relevant columns\n",
    "selected_features = ['E1SEM1', 'E1SEM2', 'E2SEM1', 'E2SEM2', 'CGPA']  # Example features\n",
    "target_column = 'E2SEM2'  # Adjust based on actual target column name\n",
    "id_column = 'ID'  # Adjust based on actual ID column name\n",
    "name_column = 'NAME'  # Adjust based on actual NAME column name\n",
    "\n",
    "features = data[selected_features]\n",
    "target = data[target_column]\n",
    "\n",
    "# Step 3: Handle Missing Data (Optional)\n",
    "# Drop rows with null values in selected features or target\n",
    "features.dropna(inplace=True)\n",
    "target = target[features.index]  # Keep target aligned with features\n",
    "\n",
    "# Step 4: Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(features)\n",
    "\n",
    "# Step 5: Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 7: Model Selection - Gradient Boosting Regressor with Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MAE from Grid Search:\", -grid_search.best_score_)\n",
    "\n",
    "# Best model after tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 8: Define a Prediction Function\n",
    "def predict_next_semester_marks(student_id=None, student_name=None):\n",
    "    # Find the student row\n",
    "    if student_id:\n",
    "        student_row = data[data[id_column] == student_id]\n",
    "    elif student_name:\n",
    "        student_row = data[data[name_column] == student_name]\n",
    "    else:\n",
    "        raise ValueError(\"Please provide either a student_id or student_name.\")\n",
    "    \n",
    "    if student_row.empty:\n",
    "        return \"Student not found.\"\n",
    "    \n",
    "    # Extract features for the student\n",
    "    student_features = student_row[selected_features]\n",
    "    \n",
    "    # Handle missing data if necessary\n",
    "    if student_features.isnull().values.any():\n",
    "        return \"Student data contains missing values.\"\n",
    "    \n",
    "    # Apply polynomial features and scaling\n",
    "    student_poly = poly.transform(student_features)\n",
    "    student_scaled = scaler.transform(student_poly)\n",
    "    \n",
    "    # Predict next semester marks\n",
    "    prediction = best_model.predict(student_scaled)\n",
    "    return prediction[0]  # Return the prediction\n",
    "\n",
    "# Example Usage\n",
    "student_id = 'R200589'  # Replace with an actual ID\n",
    "predicted_marks = predict_next_semester_marks(student_id=student_id)\n",
    "print(f\"Predicted Next Semester Marks for Student ID {student_id}: {predicted_marks}\")\n",
    "\n",
    "# Step 9: Evaluate the Best Model on Test Set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "\n",
    "# Step 10: Cross-Validation for Robust Evaluation\n",
    "cv_scores = cross_val_score(best_model, X_poly, target, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"Cross-validated MAE:\", -cv_scores.mean())\n",
    "\n",
    "# Step 11: Visualize Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)\n",
    "plt.xlabel('Actual Next Semester Marks')\n",
    "plt.ylabel('Predicted Next Semester Marks')\n",
    "plt.title('Actual vs Predicted Next Semester Marks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 'R200256'  # Replace with an actual ID\n",
    "\n",
    "print(\"Real results are - >\", data.loc[data[\"ID\"] == student_id, \"E2SEM2\"].values[0])\n",
    "predicted_marks = predict_next_semester_marks(student_id=student_id)\n",
    "print(f\"Predicted Next Semester Marks for Student ID {student_id}: {predicted_marks}\")\n",
    "\n",
    "# Step 9: Evaluate the Best Model on Test Set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "\n",
    "# Step 10: Cross-Validation for Robust Evaluation\n",
    "# cv_scores = cross_val_score(best_model, X_poly, target, cv=5, scoring='neg_mean_absolute_error')\n",
    "# print(\"Cross-validated MAE:\", -cv_scores.mean())\n",
    "\n",
    "# # Step 11: Visualize Results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "# plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)\n",
    "# plt.xlabel('Actual Next Semester Marks')\n",
    "# plt.ylabel('Predicted Next Semester Marks')\n",
    "# plt.title('Actual vs Predicted Next Semester Marks')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = pd.read_csv(\"r20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset - Replace with your actual data\n",
    "data = pd.read_csv(\"r20.csv\")\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up features (previous semesters) and target (next semester: E3SEM1)\n",
    "features = ['E1SEM1', 'E1SEM2', 'E2SEM1']\n",
    "# Create a new column for E3SEM1 as the mean of E2SEM2 (for demonstration purposes)\n",
    "# You should replace this with actual E3SEM1 values if available\n",
    "data['E3SEM1'] = data['E2SEM1'] + 0.2  # Simulate E3SEM1 as a slight increment\n",
    "\n",
    "# Splitting data into features (X) and target (y)\n",
    "X = data[features]\n",
    "y = data['E3SEM1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set and calculate error\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting E3SEM1 for a specific student (e.g., student_id = 'R200259')\n",
    "student_id = 'R200'\n",
    "student_data = data.loc[data['ID'] == student_id, features]\n",
    "predicted_e3sem1 = model.predict(student_data)[0]\n",
    "print(f\"Predicted E3SEM1 for student ID {student_id}: {predicted_e3sem1}\")\n",
    "print(\"Actual E3s1 data from data\" , temp_data[\"E2S2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
